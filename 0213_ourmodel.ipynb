{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1-3c1yd9M_-BnKhS1UWM3d2m1yQ7S5of8",
      "authorship_tag": "ABX9TyPLAmPAVzHSHCouW+Ni0jmQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lilcob/test_colab/blob/main/0213_ourmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import PIL  # python 의 이미지 전처리 라이브러리\n",
        "import glob # 대용량, 대규모 파일을 다룰때 사용\n",
        "import os # os, path 관련 조작, 변경 , 파일 삭제 등\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2o6HAfc8gyo",
        "outputId": "68afcbe6-242e-4ff2-8127-fe8c0aac0c3d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3xIvvn4LImuI"
      },
      "outputs": [],
      "source": [
        "# 우리만의 데이터, 모델 만들어 보기\n",
        "# 두가지 카테고리 분류 (데이터 기획은 여러분 들이)\n",
        "# https://chromewebstore.google.com/detail/zzllrr-imager-geek/gfjhimhkjmipphnaminnnnjpnlneeplk\n",
        "# 이미저 긱 설치\n",
        "# 이미지 검색 -> 우측 상단 아이콘 버튼 클릭 GO -> 필요 없는 이미지 클릭해서 제거\n",
        "# Rename 버튼 클릭후, -> prefix 명명규칙 수정 -> save 버튼 눌러서 저장\n",
        "# 각각 카테고리에 이미지 500장\n",
        "# 두 폴더 압축하기\n",
        "# 압축한 폴더를 드라이브에 압축한 파일 업로드\n",
        "# google drive 마운트 , colab 옆 폴더 마크 , 상단 google drive mount 버튼 클릭\n",
        "# 업로드한 압축 파일이 있는지 확인."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/drive/MyDrive/ourdatset.zip\n",
        "!mkdir dataset"
      ],
      "metadata": {
        "id": "rXd2uccBJXiB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/ourdatset.zip -d dataset"
      ],
      "metadata": {
        "id": "dDmN6sClYy5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataset_folder_path = '/content/dataset'\n",
        "category_cnt = len(os.listdir(dataset_folder_path))\n",
        "print(os.listdir(dataset_folder_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnhgj2t5ZMGh",
        "outputId": "53ece9dc-9371-4a2f-c432-190b1a72b592"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PNEUMONIA', 'NORMAL']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **glob.glob(dataset_folder_path+'/*/*')**\n",
        "*   파일의 경로+/* 을 입력하면 해당 폴더 하위\n",
        "*   경로 상에 있는 모든 파일을 리스트로 리턴\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "ex) dataset_folder_path+'/*/*' -> 하위 폴더의 하위 데이터 전체 리턴\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Ky6F07hmpoaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = []\n",
        "y = []\n",
        "\n",
        "for label,folder in enumerate(os.listdir(dataset_folder_path)):\n",
        "\n",
        "    # print(dataset_folder_path +'/'+ folder) 좋은 코드가 아님\n",
        "    # os.path.join(dataset_folder_path , folder)) # 유지 보수 좋은 코드\n",
        "\n",
        "    folder_full_path = os.path.join(dataset_folder_path , folder)\n",
        "    all_files = glob.glob(folder_full_path + '/*.jpeg')\n",
        "    all_files_jpg = glob.glob(folder_full_path + '/*.jpg')\n",
        "    all_files_png = glob.glob(folder_full_path + '/*.png')\n",
        "    all_files.extend(all_files_jpg)\n",
        "    all_files.extend(all_files_png)\n",
        "\n",
        "    for idx,file_full_path in enumerate(all_files):\n",
        "        image = PIL.Image.open(file_full_path)\n",
        "        image = image.resize((64,64))\n",
        "        image = image.convert('RGB')\n",
        "        data = np.asarray(image)\n",
        "        x.append(data)\n",
        "        y.append(label)\n",
        "        if idx % 30 == 0:\n",
        "            print(idx,'/',len(all_files))"
      ],
      "metadata": {
        "id": "cQlWl8_gbX_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "print('카테고리 갯수',np.bincount(y))\n",
        "print('전처리 확인',x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rgi8gcTJfSWq",
        "outputId": "fe26cc38-eb30-4cfe-87d9-e6a47622ba7e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "카테고리 갯수 [3875 1341]\n",
            "전처리 확인 (5216, 64, 64, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "Nqz4hllvm44H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 개발 팁 , 전처리 시간이 너무 오래 걸린다면(데이터 늘어 나서)\n",
        "# xy = (x_train, x_test, y_train, y_test)\n",
        "# np.save('/content/drive/MyDrive/preprocessing_data.npy',xy)\n",
        "# x_train,x_test,y_train,y_test = np.load('/content/drive/MyDrive/preprocessing_data.npy')"
      ],
      "metadata": {
        "id": "Jm_8DuESnjzy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train / 255.\n",
        "x_test = x_test / 255."
      ],
      "metadata": {
        "id": "LqCP5NmgoUUq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 구글넷 실습(오전에 진행한)\n",
        "# 레즈넷 실습(다 짜여진 코드) -> fine tuning"
      ],
      "metadata": {
        "id": "exCXzi1torry"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 개선의 여지 해상도 수정 ( 전처리 도 수정 해야 함)\n",
        "input_layer = layers.Input(shape = (64,64,3), name='start_layer')\n",
        "\n",
        "# 개선의 여지 conv2d 수정 성능이 매우 잘 나온다면 -모델 다이어트\n",
        "# 성능이 안나온다면 channel 수, 레이어 추가\n",
        "tower_1 = layers.Conv2D(64, kernel_size = (1,1) , padding='same' , activation= 'relu')(input_layer)\n",
        "\n",
        "tower_2 = layers.Conv2D(64, kernel_size = (1,1) , padding='same' , activation= 'relu')(input_layer)\n",
        "tower_2 = layers.Conv2D(64, kernel_size = (3,3) , padding='same' , activation= 'relu')(tower_2)\n",
        "\n",
        "tower_3 = layers.Conv2D(64, kernel_size = (1,1) , padding='same' , activation= 'relu')(input_layer)\n",
        "tower_3 = layers.Conv2D(64, kernel_size = (5,5) , padding='same' , activation= 'relu')(tower_3)\n",
        "\n",
        "tower_4 = layers.MaxPool2D(pool_size=(3,3), strides=(1,1) , padding='same')(input_layer)\n",
        "tower_4 = layers.Conv2D(64, kernel_size=(1,1) , padding='same' , activation='relu')(tower_4)\n",
        "\n",
        "concat_layer = layers.concatenate([tower_1, tower_2,tower_3,tower_4], axis=3)\n",
        "\n",
        "tower_2_1 = layers.Conv2D(120, kernel_size = (1,1) , padding='same' , activation= 'relu')(concat_layer)\n",
        "\n",
        "tower_2_2 = layers.Conv2D(120, kernel_size = (1,1) , padding='same' , activation= 'relu')(concat_layer)\n",
        "tower_2_2 = layers.Conv2D(120, kernel_size = (3,3) , padding='same' , activation= 'relu')(tower_2_2)\n",
        "\n",
        "tower_2_3 = layers.Conv2D(120, kernel_size = (1,1) , padding='same' , activation= 'relu')(concat_layer)\n",
        "tower_2_3 = layers.Conv2D(120, kernel_size = (5,5) , padding='same' , activation= 'relu')(tower_2_3)\n",
        "\n",
        "tower_2_4 = layers.MaxPool2D(pool_size=(3,3), strides=(1,1) , padding='same')(concat_layer)\n",
        "tower_2_4 = layers.Conv2D(120, kernel_size=(1,1) , padding='same' , activation='relu')(tower_2_4)\n",
        "\n",
        "final_concat_layer = layers.concatenate([tower_2_1, tower_2_2,tower_2_3,tower_2_4], axis=3)\n",
        "average_pooling_layer = layers.AveragePooling2D(pool_size=(16,16),strides=(16,16))(final_concat_layer)\n",
        "flat_layer = layers.Flatten()(average_pooling_layer)\n",
        "\n",
        "# 개선의 여지 -  Dense 층 추가\n",
        "output_layer = layers.Dense(1 , activation = 'sigmoid')(flat_layer)\n",
        "\n",
        "google_net_model = models.Model(inputs = input_layer, outputs = output_layer)\n",
        "google_net_model.summary()"
      ],
      "metadata": {
        "id": "cQO7niNHoxjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#개선 여지 hyper parameter tuning\n",
        "# ex ) tf.keras.optimizers.Adam()\n",
        "google_net_model.compile(loss='binary_crossentropy',\n",
        "                         optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "KZZGArIj9VkA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_point_path = '/content/drive/MyDrive/ourmodel_checkpoint'\n",
        "mc = tf.keras.callbacks.ModelCheckpoint(check_point_path,\n",
        "                                   monitor='val_loss',\n",
        "                                   save_best_only=True)\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4)"
      ],
      "metadata": {
        "id": "ND6YQQFn_fto"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_net_model.fit(x_train,y_train, batch_size=32,\n",
        "                     epochs=20,\n",
        "                     callbacks=[mc,es],\n",
        "                     validation_data=(x_test,y_test))"
      ],
      "metadata": {
        "id": "5VNrb8kP9WfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## our model inference code\n",
        "# inference만 진행 할 시, 가장 위 import library 실행 -> 모델 빌드 하는 부분 실행\n",
        "google_net_model.load_weights('/content/drive/MyDrive/ourmodel_checkpoint')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDpE7khU-3p4",
        "outputId": "d49fd2f7-6e3d-4af2-a168-1fe651225f70"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7a482194bcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "f = files.upload()"
      ],
      "metadata": {
        "id": "FzJD8nccEud5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = list(f.keys())[0]\n",
        "test_img = PIL.Image.open(file_name)\n",
        "test_img = test_img.resize((64,64))\n",
        "test_img = test_img.convert('RGB')\n",
        "data = np.asarray(test_img)\n",
        "test_image_tensor = np.array([data])\n",
        "test_image_tensor = test_image_tensor / 255.\n",
        "test_image_tensor.shape"
      ],
      "metadata": {
        "id": "7_dnQqQNJs8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = google_net_model.predict(test_image_tensor)\n",
        "result[0][0]\n",
        "if result[0][0] > 0.5:\n",
        "    print(f'{result[0][0] * 100} % 확률로 정상 폐로 판단이 됩니다.')\n",
        "else:\n",
        "    print(f'{ (1 - result[0][0]) * 100} % 폐 질환이 예측 됩니다.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1a3y5DLJ0w6",
        "outputId": "604c570f-0aef-4b7c-effd-983f80193597"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 54ms/step\n",
            "99.97873264801456 % 폐 질환이 예측 됩니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EXAxl2CDMLaU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}